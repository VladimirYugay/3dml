{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Surface Representations and Shape Alignment\n",
    "\n",
    "\n",
    "We will go over a few basic geometric tasks including hand-crafted shape generation and conversion between representations as well as simple shape alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import k3d\n",
    "import trimesh\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Generating Signed Distance Fields\n",
    "\n",
    "### (a) SDF for a Sphere\n",
    "The visualization below shows on the right a slice through the SDF representation of the sphere on the left (positive values in blue, negative in red, close to zero as gray).\n",
    "\n",
    "Sphere Mesh | Sphere SDF\n",
    ":- | :-\n",
    "<img src=\"exercise_1/images/sphere_mesh.png\" alt=\"sphere_mesh\" style=\"width: 250px;\"/> | <img src=\"exercise_1/images/sphere_sdf.png\" alt=\"sphere_sdf\" style=\"width: 250px;\"/>\n",
    "\n",
    "In this part of the exercise, we do not yet aim to create a grid of SDF values but instead first focus on the evaluation at sparse 3D point locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.implicit_function import signed_distance_sphere\n",
    "\n",
    "sphere_radius = 0.35\n",
    "sphere_center = [0, 0, 0]\n",
    "\n",
    "# sdf value at point [0, 0, 0], i.e. at the center of the sphere should have a negative sdf\n",
    "x, y, z = 0, 0, 0\n",
    "print(f'SDF inside the sphere:', signed_distance_sphere(x, y, z, sphere_radius, sphere_center[0], sphere_center[1], sphere_center[2]))\n",
    "\n",
    "# sdf value at point [0, 0, 0.35], i.e. on the surface of the sphere should have sdf value zero\n",
    "x, y, z = 0, 0, 0.35\n",
    "print(f'SDF at surface of the sphere: ', signed_distance_sphere(x, y, z, sphere_radius, sphere_center[0], sphere_center[1], sphere_center[2]))\n",
    "\n",
    "# sdf value at point [0, 0.4, 0], i.e. outside the sphere should have a positive sdf value\n",
    "x, y, z = 0, 0.4, 0\n",
    "print(f'SDF outside the sphere:', signed_distance_sphere(x, y, z, sphere_radius, sphere_center[0], sphere_center[1], sphere_center[2]))\n",
    "\n",
    "# your function should be able to handle numpy arrays as point coordinate inputs\n",
    "# let's pass all three points for vectorize inference\n",
    "x = np.array([0, 0, 0])\n",
    "y = np.array([0, 0, 0.4])\n",
    "z = np.array([0, 0.35, 0])\n",
    "print('SDF for given points:', signed_distance_sphere(x, y, z, sphere_radius, sphere_center[0], sphere_center[1], sphere_center[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) SDF for a Torus\n",
    "\n",
    "Torus Mesh | Torus SDF (abs(sdf) > 0.1 not shown)\n",
    ":- | :-\n",
    "<img src=\"exercise_1/images/torus_mesh.png\" alt=\"torus_mesh\" style=\"width: 250px;\"/> | <img src=\"exercise_1/images/torus_sdf.png\" alt=\"torus_sdf\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.implicit_function import signed_distance_torus\n",
    "\n",
    "torus_minor_radius = 0.035\n",
    "torus_major_radius = 0.35\n",
    "torus_center = [0, 0, 0]\n",
    "\n",
    "# let's define a few test points: \n",
    "# inside the torus (0, 0, 0.35), \n",
    "# surface of the torus (0, 0, 0.385)  \n",
    "# outside the torus (0, 0, 0)\n",
    "x = np.array([0, 0, 0, 0])\n",
    "y = np.array([0, 0, 0, 0])\n",
    "z = np.array([0.35, 0.385, 0, 0])\n",
    "print('SDF for given points:', signed_distance_torus(x, y, z, torus_major_radius, torus_minor_radius, *torus_center))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Composition of SDFs\n",
    "We'll represent the proton and the electron with spheres, and the orbit of the electron as a thin torus.\n",
    "\n",
    "Atom Mesh | Atom SDF (abs(sdf) > 0.1 not shown)\n",
    ":- | :-\n",
    "<img src=\"exercise_1/images/atom_mesh.png\" alt=\"atom_mesh\" style=\"width: 250px;\"/> | <img src=\"exercise_1/images/atom_sdf.png\" alt=\"atom_sdf\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.implicit_function import signed_distance_atom\n",
    "\n",
    "# size and placement of shapes is specified in the signed_distance_atom function\n",
    "# points x, y, z = (0, 0, 0), (0, 0, 0.35) should both lie inside the composite shape\n",
    "# (0, 0, 1.75) outside\n",
    "x = np.array([0, 0, 0])\n",
    "y = np.array([0, 0, 0])\n",
    "z = np.array([0, 0.35, 0.175])\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "print('SDF for given points:', signed_distance_atom(x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) SDF Grids and Visualization\n",
    "\n",
    "It is usually more practical to represent a shape in a discrete volumetric grid where each voxel contains one SDF value, pointing towards the closest surface. \n",
    "\n",
    "Our visualization function outputs color-coded cubes for each voxel in the grid: Small blue cubes for positive values (outside the surface) and bigger red cubes for negative values (inside the surface).\n",
    "Cubes very close to the surface are colored in white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.sdf_grid import sdf_grid\n",
    "from e1.util.visualization import visualize_sdf\n",
    "\n",
    "# We use a resolution of 32x32x32 for our grid here. \n",
    "# You can also try out different values but note that higher resolutions take significantly \n",
    "# more time for generating and exporting the grid.\n",
    "resolution = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sphere SDF Grid\n",
    "sdf_func_sphere = lambda x, y, z: signed_distance_sphere(x, y, z, sphere_radius, sphere_center[0], sphere_center[1], sphere_center[2])\n",
    "sphere_sdf_grid = sdf_grid(sdf_func_sphere, resolution)\n",
    "visualize_sdf(sphere_sdf_grid, filename=Path.cwd() / 'sphere_sdf.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Torus SDF Grid|\n",
    "sdf_func_torus = lambda x, y, z: signed_distance_torus(x, y, z, torus_major_radius, torus_minor_radius, torus_center[0], torus_center[1], torus_center[2])\n",
    "torus_sdf_grid = sdf_grid(sdf_func_torus, resolution)\n",
    "visualize_sdf(torus_sdf_grid, filename=Path.cwd() / 'torus_sdf.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Atom SDF Grid\n",
    "# Here, your might notice that a resolution of 32x32x32 or lower is not sufficient to represent the outer ring of the atom.\n",
    "# This is a common problem especially with machine learning methods that are limited to such a low resolution as we will see in future lectures.\n",
    "atom_sdf_grid = sdf_grid(signed_distance_atom, resolution)\n",
    "visualize_sdf(atom_sdf_grid, filename=Path.cwd() / 'atom_sdf.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. From Signed Distance Fields to Occupancy Grids\n",
    "We can also represent shapes by encoding occupancy instead of SDF values. Used in a grid structure, this leads us to Occupancy Grids which simply encode for each voxel if it is inside or outside the represented shape. This has certain advantages and disadvantages compared to SDF grids, especially for learned methods as we will see in later lectures.\n",
    "\n",
    "### (a) Converting SDF Grids to Occupancy Grids\n",
    "We consider here an Occupancy Grid as a binary 3D grid with value 0 for voxels outside the shape and 1 for voxels inside. Given an SDF of a shape, converting the shape to an occupancy grid is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.occupancy_grid import occupancy_grid\n",
    "from e1.util.visualization import visualize_occupancy, visualize_pointcloud, visualize_mesh\n",
    "\n",
    "# Here, we use a grid of 128x128x128\n",
    "resolution = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sphere Occupancy Grid\n",
    "sphere_occ_grid = occupancy_grid(sdf_func_sphere, resolution)\n",
    "visualize_occupancy(sphere_occ_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Torus Occupancy Grid\n",
    "torus_occ_grid = occupancy_grid(sdf_func_torus, resolution)\n",
    "visualize_occupancy(torus_occ_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Atom Occupancy Grid\n",
    "atom_occ_grid = occupancy_grid(signed_distance_atom, resolution)\n",
    "visualize_occupancy(atom_occ_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Implicit Functions for more complex shapes\n",
    "\n",
    "The SDF functions you implemented and used so far encode only simple shapes which could be represented by rather straight-forward mathematical functions. What if we need to represent a complex shape, e.g. the stanford bunny? It's hard to come up with an elegant mathematical equation in this case.\n",
    "\n",
    "One way to figure out such implicit shape function is to <em>learn</em> the function in a supervised way. In later lectures, we'll go over works like DeepSDF [1] and Occupancy Networks [2] which are seminal works showing how to represent and learn SDF/Occupancy functions with deep neural networks.\n",
    "\n",
    "For now let's try running your occupancy grid extraction method on a learned function to represent a complex shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.util.mlp.model import signed_distance_mlp\n",
    "\n",
    "# runs on cpu, so might be slow\n",
    "shape_grid = occupancy_grid(signed_distance_mlp, resolution)\n",
    "visualize_occupancy(shape_grid, flip_axes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those curious on how to train such a function, a minimal sample implementation is provided [here](https://github.com/nihalsid/shape_sdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. From Signed Distance Fields to Triangle Meshes\n",
    "\n",
    "Operating on regular voxel grids with either SDFs or Occupancy Grids has many advantages as you will also see in later exercises.\n",
    "\n",
    "However, eventually we want to be able to extract the shape encoded in an implicit representation into an explicit format that can be viewed more easily and is more widely supported by graphics pipelines. This is where polygon (or more specifially, triangle) meshes come into play.\n",
    "\n",
    "Marching Cubes iteratively loops over all cubes defined between the voxels of a regular grid.\n",
    "\n",
    "For each such cube, it does the following:\n",
    "- Compute an 8-bit index representing the specific configuration of its corners (storing for each corner whether it lies inside or outside of the shape)\n",
    "- Using this index, retreive information about where and how triangles intersect the cube edges from a pre-computed table\n",
    "- Add found vertices and faces to a global list\n",
    "\n",
    "We will use the following edge and corner indices for our implementation:\n",
    "\n",
    "<center><img src=\"exercise_1/images/mc_indices.png\" alt=\"Marching Cubes Indices\" style=\"width: 250px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Compute the Cube Index\n",
    "\n",
    "The function takes a cube, represented by a list of SDF values from the corners of the cube. The order is given by the corner indices visualized above.\n",
    "\n",
    "For each corner, you should set the corresponding bit to 1 if that corner's SDF value is < 0 and to 1 otherwise.\n",
    "\n",
    "Example: A cube intersects the surface such that its top half lies within the shape (= top 4 corner voxels hold negative SDF values) and the bottom half outside (= bottom 4 corner voxels hold positive SDF values).\n",
    "\n",
    "Its index should then be 11110000 = 240.\n",
    "\n",
    "Note that corner 0 in your list of SDF values modifies the least significant bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.marching_cubes import compute_cube_index\n",
    "\n",
    "cube = np.array([-1, -1, -1, -1, 1, 1, 1, 1])\n",
    "index = compute_cube_index(cube)\n",
    "print(f\"Cube Index for {cube} = {index:08b}(={index})\")\n",
    "\n",
    "# This is the example from above\n",
    "cube = np.array([1, 1, 1, 1, -1, -1, -1, -1])\n",
    "index = compute_cube_index(cube)\n",
    "print(f\"Cube Index for {cube} = {index:08b}(={index})\")\n",
    "\n",
    "# Take a look at the triangle_table. How many triangles are defined for this index?\n",
    "cube = np.array([1, 1, 1, 1, 1, 1, 1, 1])\n",
    "index = compute_cube_index(cube)\n",
    "print(f\"Cube Index for {cube} = {index:08b}(={index})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Implement Marching Cubes\n",
    "Now that we have the index, all that is left to do is to use the pre-defined triangle table that tells us which edges are intersected in the current cube.\n",
    "\n",
    "We then add these face definitions to a global table. Additionally, we have to add the vertices defined in the middle of each intersected edge to a second global list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.marching_cubes import marching_cubes\n",
    "from e1.util.visualization import visualize_mesh\n",
    "\n",
    "sdf_grid_sphere = sdf_grid(sdf_func_sphere, 32)\n",
    "vertices, faces = marching_cubes(sdf_grid_sphere)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Vertex Interpolation\n",
    "\n",
    "Your output should look like the left image in the visualization below.\n",
    "\n",
    "One thing we still have to take care of is to reduce the effect of the grid structure. In your implementation so far, the vertex locations were set to lie exactly half way between the two corners of an edge.\n",
    "\n",
    "One trick to reduce the amount of grid artifacts in our mesh is to interpolate the vertex locations based on their relative SDF values since each such value tells us precisely where the surface should lie.\n",
    "\n",
    "Change the implementation of function `vertex_interpolation` in file `exercise_1/marching_cubes.py` to interpolate the vertex location based on corner points p_1 and p_2 as well as their corresponding SDF values v_1 and v_2.\n",
    "\n",
    "Run your Marching Cubes implementation again with the modified function below. Your output should now look much smoother, like on the right side of the visualization below.\n",
    "\n",
    "No Interpolation | Interpolation\n",
    ":- | :-\n",
    "<img src=\"exercise_1/images/mc_no_interpolation.png\" alt=\"no interpolation\" style=\"width: 250px;\"/> | <img src=\"exercise_1/images/mc_interpolation.png\" alt=\"interpolation\" style=\"width: 250px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vertices, faces = marching_cubes(sdf_grid_sphere)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also play around with your torus and atom shapes below.\n",
    "\n",
    "Try out the effects of different resolutions and how vertex interpolation affects things there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sdf_grid_sphere = sdf_grid(sdf_func_sphere, 128)\n",
    "vertices, faces = marching_cubes(sdf_grid_sphere)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sdf_grid_torus = sdf_grid(sdf_func_torus, 64)\n",
    "vertices, faces = marching_cubes(sdf_grid_torus)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that the orbit of the atom is not preserved at 64^3 resolution or lower, try going higher in resolution, e.g. 128 (will be much slower)\n",
    "sdf_grid_atom = sdf_grid(signed_distance_atom, 64)\n",
    "vertices, faces = marching_cubes(sdf_grid_atom)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# runs on cpu, so might be slow\n",
    "sdf_grid_mlp = sdf_grid(signed_distance_mlp, 64)\n",
    "vertices, faces = marching_cubes(sdf_grid_mlp)\n",
    "visualize_mesh(np.concatenate(vertices), np.stack(faces), flip_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Writing Triangle Meshes to Disk as Wavefront OBJ\n",
    "\n",
    "Triangle meshes are simple data structures that can easily be stored in common data formats like OBJ.\n",
    "\n",
    "In this format, each line simply starts with a _v_ if it defines a vertex or _f_ if it defines a face.\n",
    "The letter is then followed by three float values (written as strings) denoting the x, y, and z locations for a vertex or three integer values denoting the indices of the vertices that are part of this triangle face. All values are separated by a space.\n",
    "\n",
    "Minimal example:\n",
    "```\n",
    "v 1.0 2.0 3.0\n",
    "v 2.0 3.0 4.0\n",
    "v 3.0 4.0 5.0\n",
    "f 0 1 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices, faces = marching_cubes(sdf_grid_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.export import export_mesh_to_obj\n",
    "\n",
    "export_mesh_to_obj(\"exported_mesh.obj\", vertices, faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. From Triangle Meshes to Point Clouds\n",
    "\n",
    "Point clouds are another 3D representation popular because of their simplicity and efficiency, and are quite often the output format provided by 3D capturing devices. In the lecture we discussed one way to sample point clouds from meshes by sampling uniformly across the mesh surface.\n",
    "\n",
    "This can be done by first determining the number of points we need to sample for each triangle, based on its surface area. Then, we sample that number of points using barycentric coordinates for each triangle by generating random numbers between 0 and 1 for r_1 and r_2 and then apply the formulas $$u=1-\\sqrt{r_1}, v=\\sqrt{r_1}(1-r_2), w=\\sqrt{r_1}r_2, P=uA+vB+wC$$ to get the coordinates of the sampled point **P**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_grid_atom = sdf_grid(signed_distance_atom, 64)\n",
    "vertices, faces = marching_cubes(sdf_grid_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.point_cloud import sample_point_cloud\n",
    "\n",
    "n_points = 5000\n",
    "sampled_points = sample_point_cloud(vertices, faces, n_points)\n",
    "visualize_pointcloud(sampled_points, .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "MeshLab supports viewing point clouds stored as OBJ files. Since we don't have any faces, we can store only the vertices in the OBJ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.export import export_pointcloud_to_obj\n",
    "\n",
    "# export to \"exported_pointcloud.obj\", check out the mesh in MeshLab\n",
    "export_pointcloud_to_obj(\"exported_pointcloud.obj\", sampled_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Rigid Shape Aligment with Procrustes\n",
    "\n",
    "Here we'll try to align the following two shapes, given near-perfect point correspondences between the shapes. Note that when working with real data, more involved methods like ICP are required since neither correspondences nor shape overlap will be perfect.\n",
    "\n",
    "Executing the cell below shows a visualization of the two shapes in their current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from e1.util.visualization import visualize_shape_alignment\n",
    "visualize_shape_alignment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the function `procrustes_align` in `exercise_1/alignment.py` such that this function returns the rigid transformation from input (red) to target (green). It should return a rotation R and translation t which you can then use to visualize the final shape alignment using our pre-defined function `visualize_shape_alignment`.\n",
    "\n",
    "The function already takes in the correspondences, so you don't have to worry about that.\n",
    "\n",
    "For the given meshes and correspondences you should be able to get close to 0 aligment loss and almost perfect aligment of the meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from e1.alignment import procrustes_align, load_correspondences\n",
    "from e1.util.visualization import visualize_shape_alignment\n",
    "\n",
    "# load correspondences\n",
    "correspondences_x, correspondences_y = load_correspondences()\n",
    "# align correspondences, in case of perfect aligment should be very close to zero (< 1e-8)\n",
    "R, t = procrustes_align(correspondences_x, correspondences_y)\n",
    "\n",
    "# perfect aligment would cause perfect superimposition of the two meshes\n",
    "# perfect aligment (on my system) appears as green mesh with gliching red colors when changing the viewing angle\n",
    "visualize_shape_alignment(R, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Park, Jeong Joon, et al. \"Deepsdf: Learning continuous signed distance functions for shape representation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019\n",
    "\n",
    "[2] Mescheder, Lars, et al. \"Occupancy networks: Learning 3d reconstruction in function space.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.\n",
    "\n",
    "[3] Lorensen, William E., and Harvey E. Cline. \"Marching cubes: A high resolution 3D surface construction algorithm.\" ACM siggraph computer graphics 21.4 (1987): 163-169.\n",
    "\n",
    "[4] Schönemann, Peter H. \"A generalized solution of the orthogonal procrustes problem.\" Psychometrika 31.1 (1966): 1-10.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
